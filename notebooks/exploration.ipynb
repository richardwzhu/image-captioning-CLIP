{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09599b92-e2e4-4f7d-91ae-0981fca3f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_utils import preprocess, make_train_valid_dfs, build_loaders\n",
    "from config import default_config\n",
    "from clip_utils import CLIPModel\n",
    "from train_eval_utils import train_epoch, valid_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f80402-4e1d-48b8-8ed1-6c737f3538a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_name='image-captioning-CLIP'\n",
      "exp_name='exp_1a'\n",
      "device='cpu'\n",
      "config={'raw_file_path': '../input/raw/flickr30k/results.csv', 'clean_file_path': '../input/clean/flickr30k/captions.csv', 'image_path': '../input/raw/flickr30k/Images', 'train_size': 0.8, 'batch_size': 32, 'num_workers': 4, 'image_encoder_lr': 0.0001, 'text_encoder_lr': 1e-05, 'projection_head_lr': 0.001, 'weight_decay': 0.001, 'patience': 1, 'factor': 0.8, 'epochs': 2, 'device': 'cuda:0', 'image_size': 224, 'text_tokenizer': 'distilbert-base-uncased', 'max_length': 200, 'image_encoder': 'resnet50', 'text_encoder': 'distilbert-base-uncased', 'pretrained': True, 'trainable': True, 'image_embedding': 2048, 'text_embedding': 768, 'projection_dim': 256, 'dropout': 0.1, 'temperature': 1}\n"
     ]
    }
   ],
   "source": [
    "project_name = 'image-captioning-CLIP'\n",
    "exp_name = 'exp_1a'\n",
    "config = default_config\n",
    "device = \"cpu\"\n",
    "print(f'{project_name=}\\n{exp_name=}\\n{device=}')\n",
    "print(f'{config=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c695272-d664-4337-9588-b15b1e1692be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created clean csv file ../input/clean/flickr30k/captions.csv\n"
     ]
    }
   ],
   "source": [
    "preprocess(config['raw_file_path'], 1)\n",
    "train_df, valid_df = make_train_valid_dfs(config[\"clean_file_path\"], 0.8)\n",
    "train_df, valid_df = train_df[:128], valid_df[:64]\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(config['text_tokenizer'])\n",
    "train_loader = build_loaders(train_df, tokenizer, mode=\"train\", config=config)\n",
    "valid_loader = build_loaders(valid_df, tokenizer, mode=\"train\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57bcd1ad-7e61-4b95-8c56-c6d304e7d34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrichzhu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/richardzhu/Desktop/Files/NYU/DL/final project/image-captioning-CLIP/notebooks/wandb/run-20230422_162739-y30c5ni1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/richzhu/image-captioning-CLIP-notebooks/runs/y30c5ni1' target=\"_blank\">rural-firebrand-3</a></strong> to <a href='https://wandb.ai/richzhu/image-captioning-CLIP-notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/richzhu/image-captioning-CLIP-notebooks' target=\"_blank\">https://wandb.ai/richzhu/image-captioning-CLIP-notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/richzhu/image-captioning-CLIP-notebooks/runs/y30c5ni1' target=\"_blank\">https://wandb.ai/richzhu/image-captioning-CLIP-notebooks/runs/y30c5ni1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact exp_1a:latest, 346.44MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099b8886bf284174b0eb9bb693e0e52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rural-firebrand-3</strong> at: <a href='https://wandb.ai/richzhu/image-captioning-CLIP-notebooks/runs/y30c5ni1' target=\"_blank\">https://wandb.ai/richzhu/image-captioning-CLIP-notebooks/runs/y30c5ni1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230422_162739-y30c5ni1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c340af06e96f41db9214fe9e61f25d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016723432633333365, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/richardzhu/Desktop/Files/NYU/DL/final project/image-captioning-CLIP/notebooks/wandb/run-20230422_162748-5dijzuxv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/richzhu/image-captioning-CLIP/runs/5dijzuxv' target=\"_blank\">generous-field-6</a></strong> to <a href='https://wandb.ai/richzhu/image-captioning-CLIP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/richzhu/image-captioning-CLIP' target=\"_blank\">https://wandb.ai/richzhu/image-captioning-CLIP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/richzhu/image-captioning-CLIP/runs/5dijzuxv' target=\"_blank\">https://wandb.ai/richzhu/image-captioning-CLIP/runs/5dijzuxv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact(f'richzhu/{project_name}/{exp_name}:latest',\n",
    "                            type='model')\n",
    "artifact_dir = artifact.download()\n",
    "run.finish()\n",
    "\n",
    "run = wandb.init(project='image-captioning-CLIP', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d59c2d4-6f33-4a35-9fcb-26dbdc84f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = CLIPModel(config)\n",
    "model.load_state_dict(torch.load(f'{artifact_dir}/{exp_name}.pt'))\n",
    "model.to(device)\n",
    "\n",
    "params = [\n",
    "    {\"params\": model.image_encoder.parameters(),\n",
    "     \"lr\": config['image_encoder_lr']},\n",
    "    {\"params\": model.text_encoder.parameters(),\n",
    "     \"lr\": config['text_encoder_lr']},\n",
    "    {\"params\": itertools.chain(\n",
    "        model.image_projection.parameters(), model.text_projection.parameters()\n",
    "    ), \"lr\": config['projection_head_lr'],\n",
    "        \"weight_decay\": config[\"weight_decay\"]\n",
    "    }\n",
    "]\n",
    "optimizer = torch.optim.AdamW(params, weight_decay=0.)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", patience=config['patience'], factor=config['factor']\n",
    ")\n",
    "step = \"epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da503cb-1b67-4a2c-af2f-948a0e7ac2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2209274ee90c44f09dc582e88c878dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979a01c8988849ffb56eb56fb1ffe862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model!\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ad5b1f8f964c2cba95f1de0b9b559a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd00f89ca3c45c798d842db22920b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Model!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">generous-field-6</strong> at: <a href='https://wandb.ai/richzhu/image-captioning-CLIP/runs/5dijzuxv' target=\"_blank\">https://wandb.ai/richzhu/image-captioning-CLIP/runs/5dijzuxv</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230422_162748-5dijzuxv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_loss = float('inf')\n",
    "for epoch in range(config['epochs']):\n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    model.train()\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, lr_scheduler,\n",
    "                             step, device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = valid_epoch(model, valid_loader, device)\n",
    "\n",
    "    if valid_loss.avg < best_loss:\n",
    "        best_loss = valid_loss.avg\n",
    "        torch.save(model.state_dict(), f'../models/{exp_name}.pt')\n",
    "        artifact = wandb.Artifact(exp_name, type='model')\n",
    "        artifact.add_file(f'../models/{exp_name}.pt')\n",
    "        run.log_artifact(artifact)\n",
    "        print(\"Saved Best Model!\")\n",
    "\n",
    "    lr_scheduler.step(valid_loss.avg)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137022cc-3ad5-4aff-bc27-5dab0e2219cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
